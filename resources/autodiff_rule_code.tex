\begin{python}
class E(torch.autograd.Function):
    @staticmethod
    def loss_fn(y, net):
        loss = torch.mean((net(y) - y) ** 2)
        return loss

    @staticmethod
    def forward(ctx, y, net):
        ctx.save_for_backward(y)
        ctx.net = net

        return E.loss_fn(y, net)

    @staticmethod
    def backward(ctx, grad_output):
        y, = ctx.saved_tensors
        net = ctx.net

        y2 = net(y)
        y3 = net(y2)
        e = 3*y2 - 2*y3 - y
        grads = -e / e.shape[0]
        return grads * grad_output, None

class ELoss(torch.nn.Module):
    def __init__(self, net, mode):
        super(ELoss, self).__init__()
        self.net = net
        self.mode = mode

    def forward(self, y):
        return E.apply(y, self.net)
\end{python}